ğŸ¤ SignBridge AI

Unified Sign Language Translation Platform

Breaking communication barriers by translating sign language into text and speech using AI â€” in real time and from videos or images.

ğŸš€ Overview

SignBridge AI is an AI-powered platform that translates sign language gestures into readable captions and audible speech.
It supports live camera input, uploaded videos, and images, all within a single unified web interface.

This project aims to improve accessibility for the deaf and hard-of-hearing community by enabling seamless communication with the hearing world.

ğŸ¯ Key Features

âœ… Live Camera Sign Translation
âœ… Video Upload â†’ Captions + Voice Output
âœ… Image Upload â†’ Gesture Recognition
âœ… Real-time captions
âœ… Text-to-Speech (TTS)
âœ… Modular & Scalable Architecture
âœ… Web-based (No installation required)

ğŸ§  How It Works (High Level)

User selects an input mode:

Live Camera

Video Upload

Image Upload

Media is processed frame-by-frame using OpenCV

Hand landmarks are extracted using MediaPipe

Gestures are classified using trained ML logic

Output is generated as:

Text captions

Optional voice output (TTS)

Everything runs inside a Streamlit-powered web app

ğŸ—ï¸ System Architecture Diagram

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        User Browser       â”‚
â”‚  (Desktop / Mobile Web)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     Streamlit Web UI     â”‚
â”‚  - Mode Selection        â”‚
â”‚  - Video / Image Upload  â”‚
â”‚  - Live Camera Toggle    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Media Processing Layer â”‚
â”‚  (OpenCV)                â”‚
â”‚  - Frame Extraction      â”‚
â”‚  - Image Preprocessing   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Hand Landmark Detection  â”‚
â”‚  (MediaPipe Hands)       â”‚
â”‚  - Finger Tracking       â”‚
â”‚  - Keypoints Extraction â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Gesture Recognition ML   â”‚
â”‚  - Rule / Model Based    â”‚
â”‚  - Sign Classification  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Output Generation Layer  â”‚
â”‚  - Text Captions         â”‚
â”‚  - Voice (TTS)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Final Output to User    â”‚
â”‚  - On-screen captions    â”‚
â”‚  - Audio playback        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ—‚ï¸ Project Structure

signbridge-ai/
â”‚
â”œâ”€â”€ app.py                  # Main Streamlit app
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ camera.py           # Live camera processing
â”‚   â”œâ”€â”€ video.py            # Video upload processing
â”‚   â”œâ”€â”€ image.py            # Image processing
â”‚   â””â”€â”€ tts.py              # Text-to-speech logic
â”‚
â”œâ”€â”€ models/                 # Gesture models / logic
â”œâ”€â”€ requirements.txt        # Dependencies
â”œâ”€â”€ runtime.txt             # Python runtime version
â”œâ”€â”€ README.md               # Project documentation
â””â”€â”€ .gitignore

ğŸ› ï¸ Tech Stack

| Layer            | Technology                |
| ---------------- | ------------------------- |
| Frontend         | Streamlit                 |
| Computer Vision  | OpenCV                    |
| Hand Tracking    | MediaPipe                 |
| Machine Learning | Python                    |
| Text-to-Speech   | pyttsx3                   |
| Deployment       | Streamlit Community Cloud |

ğŸŒ Deployment

The application is deployed using Streamlit Community Cloud.

ğŸ”— Live Demo:
ğŸ‘‰ (Add your Streamlit app URL here)

ğŸ” Environment Variables

Create a .env file (not committed to GitHub):

GEMINI_API_KEY=your_api_key_here

API keys are securely handled and excluded from version control.

ğŸš§ Current Limitations

Live camera disabled on cloud (browser security limitation)

Gesture vocabulary currently limited (extendable)

Model accuracy improves with more training data

ğŸ”® Future Enhancements

âœ¨ Full sentence-level sign recognition
âœ¨ Multilingual speech output
âœ¨ Mobile-optimized UI
âœ¨ User-trained custom gestures
âœ¨ Dedicated backend (FastAPI)
âœ¨ Native Android/iOS apps

ğŸ† Use Cases

Deafâ€“hearing communication

Education & classrooms

Public service counters

Online meetings

Accessibility tools

ğŸ‘¨â€ğŸ’» Team

Hariom Hatwate
B.Tech CSE | AI & ML
Hackathon Finalist ğŸš€

ğŸ“œ License

This project is open-source and available under the MIT License.

â­ Final Note (For Judges)

SignBridge AI is not just a project â€” it is a step toward inclusive communication powered by AI.